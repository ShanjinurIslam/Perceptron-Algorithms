{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "MAXEPOCH = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function / split \n",
    "\n",
    "\n",
    "file = open(\"trainLinearlySeparable.txt\")\n",
    "\n",
    "lines = file.readlines()\n",
    "\n",
    "numClass, numFeature, datasetLen = 0, 0, 0\n",
    "\n",
    "dataset = []\n",
    "\n",
    "count = 0\n",
    "for line in lines:\n",
    "    if count == 0:\n",
    "        var = line.split()\n",
    "        numFeature  = int(var[0]) \n",
    "        numClass = int(var[1])\n",
    "        datasetLen = int(var[2])\n",
    "    else:\n",
    "        var = line.split()\n",
    "        data = []\n",
    "        for i in range(numFeature):\n",
    "            data.append(float(var[i]))\n",
    "        data.append(int(var[numFeature]))\n",
    "        dataset.append(data)\n",
    " \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"testLinearlySeparable.txt\")\n",
    "\n",
    "lines = file.readlines()\n",
    "test_dataset = []\n",
    "\n",
    "for line in lines:\n",
    "    var = line.split()\n",
    "    data = []\n",
    "    for i in range(numFeature):\n",
    "        data.append(float(var[i]))\n",
    "    data.append(int(var[numFeature]))\n",
    "    test_dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataset,w):\n",
    "    count_accurate = 0\n",
    "    for data in dataset:\n",
    "        x = np.array(data)\n",
    "        group = x[numFeature]\n",
    "        x[numFeature] = 1\n",
    "        x = np.array(x)\n",
    "        x = x.reshape(numFeature+1,1)\n",
    "        dot_product = np.dot(w,x)[0]\n",
    "        predicted = -1\n",
    "        if dot_product > 0:\n",
    "            predicted = 1\n",
    "        else:\n",
    "            predicted = 2\n",
    "\n",
    "        if predicted==group:\n",
    "            count_accurate += 1\n",
    "\n",
    "    print(\"Accuracy :\",float((count_accurate/len(dataset))*100))\n",
    "    \n",
    "    return float(count_accurate/len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.50919762,  9.01428613,  4.63987884,  1.97316968, -6.87962719])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42) # fixed random value\n",
    "w = np.random.uniform(-10,10,numFeature+1) # randing\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.025 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Weight :  [  7.74760553   7.03055618   1.31615004 -13.46849013  93.29537281]\n"
     ]
    }
   ],
   "source": [
    "for i in range(MAXEPOCH): \n",
    "    Y = [] # misclassify hold korar jonno <- x & Y-> set of misclassified items\n",
    "    arr_dx = [] # -1 , +1 <- delta_x \n",
    "    \n",
    "    ##\n",
    "    for i in range(datasetLen):\n",
    "        x = np.array(dataset[i]) # instance , dataset theke ekta item anchi eikhane\n",
    "        group = x[numFeature]\n",
    "        x[numFeature] = 1\n",
    "        x = x.reshape(numFeature+1,1)\n",
    "        dot_product = np.dot(w,x)[0]\n",
    "        if(group ==1 and dot_product<0):\n",
    "            Y.append(x) # missclassified e add kori\n",
    "            arr_dx.append(-1) # delta value ta append kori\n",
    "        elif(group == 2 and dot_product>0):\n",
    "            Y.append(x)\n",
    "            arr_dx.append(1)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    sum = np.zeros(numFeature+1) # bias er karon e\n",
    "    \n",
    "    for i in range(len(Y)):\n",
    "        sum += arr_dx[i]*Y[i].transpose()[0]\n",
    "    ##\n",
    "    \n",
    "    w = w - learning_rate*sum\n",
    "    \n",
    "    if len(Y) == 0:\n",
    "        break\n",
    "        \n",
    "print('Final Weight : ', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 100.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(dataset,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward and Punishment Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "w = np.random.uniform(-10,10,numFeature+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(MAXEPOCH):\n",
    "    # stochastic gradient descent\n",
    "    for i in dataset:\n",
    "        group = i[-1]\n",
    "        x = i[:-1]\n",
    "        x.append(1)\n",
    "        original = np.array(x)\n",
    "        x =  np.array(x).reshape(-1,1)\n",
    "        dot_product = np.dot(w,x)[0]\n",
    "        \n",
    "        if dot_product<0 and group == 1:\n",
    "            w = w + learning_rate * original\n",
    "            \n",
    "        elif dot_product>0 and group == 2:\n",
    "            w = w - learning_rate * original\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 100.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test(dataset,w)\n",
    "test(dataset,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pocket Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudocode\n",
    "\n",
    "1. Initialize Wp (pocket vector) with zero or any random number\n",
    "2. Assing Wo (Weight at time = 0)  to Wp\n",
    "3. Run basic perceptron learning algorithm\n",
    "4. If Wt is better classifier (less amount of misclassification than previous) store Wt to Wp\n",
    "5. Return Wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(41)\n",
    "ws = np.random.uniform(-10,10,numFeature+1)\n",
    "w = ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "\n",
    "misclassification = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(MAXEPOCH):\n",
    "    count = 0 \n",
    "    \n",
    "    # basic/ reward or punishment\n",
    "    \n",
    "    Y = [] # misclassify hold korar jonno <- x & Y-> set of misclassified items\n",
    "    arr_dx = [] # -1 , +1 <- delta_x \n",
    "    \n",
    "    ##\n",
    "    for i in range(datasetLen):\n",
    "        x = np.array(dataset[i]) # instance , dataset theke ekta item anchi eikhane\n",
    "        group = x[numFeature]\n",
    "        x[numFeature] = 1\n",
    "        x = x.reshape(numFeature+1,1)\n",
    "        dot_product = np.dot(w,x)[0]\n",
    "        if(group ==1 and dot_product<0):\n",
    "            Y.append(x) # missclassified e add kori\n",
    "            arr_dx.append(-1) # delta value ta append kori\n",
    "            count += 1\n",
    "        elif(group == 2 and dot_product>0):\n",
    "            Y.append(x)\n",
    "            arr_dx.append(1)\n",
    "            count += 1\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    sum = np.zeros(numFeature+1) # bias er karon e\n",
    "    \n",
    "    for i in range(len(Y)):\n",
    "        sum += arr_dx[i]*Y[i].transpose()[0]\n",
    "    ##\n",
    "    \n",
    "    w = w - learning_rate*sum\n",
    "    \n",
    "    if count<misclassification:\n",
    "        misclassification = count\n",
    "        ws = w # pocket algorithm\n",
    "    \n",
    "    if count == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.8114442   -4.14849081   8.07334318 -16.50441026 125.32847406]\n"
     ]
    }
   ],
   "source": [
    "print(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 100.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_dataset,ws)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
